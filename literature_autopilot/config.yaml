slr_topic: "LLM Self-Improvement"

search:
  keywords:
    - "Self-Referential Prompting"
    - "Reflective Evaluation"
    - "Iterative Self-Correction"
    - "LLM Debate"
    - "Self-Improvement LLM"
  seed_urls:
    - "https://evjang.com/2023/03/26/self-reflection.html"
    - "https://aclanthology.org/2024.naacl-long.15/"
    - "https://composable-models.github.io/llm_debate/"
    - "https://arxiv.org/abs/2402.06782"
  seed_titles:
    - "Self-Correction in Large Language Models"
    - "Self-Refine: Iterative Refinement with Self-Feedback"
    - "Improving Factuality and Reasoning in Language Models through Multiagent Debate"
    - "Self-Discover: Large Language Models Self-Compose Reasoning Structures"
  max_search_results: 50

snowballing:
  enabled: true
  depth: 2
  max_results: 50

screening:
  provider: "gemini" # or "gemini"
  model: "gemini-2.5-pro"
  double_screening: true # Set to true for higher rigor (simulates 2 reviewers)

extraction:
  model: "gemini-2.5-pro"

writing:
  model: "gemini-2.5-pro"

review:
  enabled: true
  quality_threshold: 90
  max_iterations: 5
  focus_areas:
    - "PRISMA 2020 Compliance"
    - "Depth of Analysis (methodological differences)"
    - "Quantification of Improvements"
    - "Critical Discussion"
    - "Academic Writing Quality"
    - "Certainty of Evidence (GRADE)"
    - "Literature Gaps"

analysis:
  run_visualizer: true
  run_citation_validator: true
  run_grade_assessment: true
  run_gap_identifier: true

prompts:
  screening: "literature_autopilot/prompts/screening_prompt.md"
  prescreening: "literature_autopilot/prompts/prescreening_prompt.md"
  extraction: "literature_autopilot/prompts/extraction_prompt.md"

paper_structure:
  sections:
    - "Abstract"
    - "1. Introduction"
    - "1.1 Context and Motivation"
    - "1.2 Core Mechanisms Overview"
    - "1.3 Research Questions"
    - "2. Methodology"
    - "2.1 Search Strategy and Data Sources"
    - "2.2 Inclusion and Exclusion Criteria"
    - "2.3 Data Extraction and Quality Assessment"
    - "3. Analysis of Self-Referential Prompting"
    - "3.1.1 Architectural Approaches (Evolutionary vs. Template)"
    - "3.1.2 Performance Outcomes in Reasoning Tasks"
    - "3.1.3 Limitations and Computational Costs"
    - "3.2 Analysis of Reflective Evaluation"
    - "3.2.1 Self-Correction vs. External Feedback"
    - "3.2.2 The Role of Multi-Agent Debate"
    - "3.2.3 Impact on Reliability and Safety"
    - "3.3 Analysis of Iterative Self-Correction"
    - "3.3.1 Inference-Time Refinement Strategies"
    - "3.3.2 Training-Based Self-Correction (Fine-Tuning)"
    - "3.3.3 Theoretical Models of Convergence"
    - "4. Discussion"
    - "4.1 Synthesis of Methodological Trade-offs"
    - "4.2 Generalization Capabilities across Domains"
    - "4.3 Implications for Autonomous Agents"
    - "5. Conclusion"
